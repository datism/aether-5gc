---

# TODO: running on master node for now (fix to run on multiple nodes)

- set_fact:
    systemd_network_dir: /etc/systemd/network
    systemd_system_dir: /etc/systemd/system

- name: set net.ipv4.conf.all.arp_filter to 1
  ansible.posix.sysctl:
    name: net.ipv4.conf.all.arp_filter
    value: '1'
    sysctl_set: true
    reload: true
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: set net.ipv4.conf.all.arp_ignore to 1
  ansible.posix.sysctl:
    name: net.ipv4.conf.all.arp_ignore
    value: '1'
    sysctl_set: true
    reload: true
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: set net.ipv4.conf.all.arp_announce to 2
  ansible.posix.sysctl:
    name: net.ipv4.conf.all.arp_announce
    value: '2'
    sysctl_set: true
    reload: true
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: set net.ipv4.conf.all.rp_filter to 2
  ansible.posix.sysctl:
    name: net.ipv4.conf.all.rp_filter
    value: '2'
    sysctl_set: true
    reload: true
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: copy 10-aether-access.netdev to {{ systemd_network_dir }}/10-aether-access.netdev
  template:
    src: roles/router/templates/systemd/10-aether-access.netdev
    dest: "{{ systemd_network_dir }}/10-aether-access.netdev"
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: copy 20-aether-access.network to {{ systemd_network_dir }}/20-aether-access.network
  template:
    src: roles/router/templates/systemd/20-aether-access.network
    dest: "{{ systemd_network_dir }}/20-aether-access.network"
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: copy 10-aether-core.netdev to {{ systemd_network_dir }}/10-aether-core.netdev
  template:
    src: roles/router/templates/systemd/10-aether-core.netdev
    dest: "{{ systemd_network_dir }}/10-aether-core.netdev"
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: copy 20-aether-core.network to {{ systemd_network_dir }}/20-aether-core.network
  template:
    src: roles/router/templates/systemd/20-aether-core.network
    dest: "{{ systemd_network_dir }}/20-aether-core.network"
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: find {{ core.data_iface }}'s netplan network directory
  shell: basename $(find /*/systemd/network -maxdepth 1 -not -type d -name '*{{ core.data_iface }}.network' -print)
  register: result
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: create {{ systemd_network_dir }}/{{ result.stdout }}.d
  file:
    path: "{{ systemd_network_dir }}/{{ result.stdout }}.d"
    state: directory
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: copy macvlan.conf to {{ systemd_network_dir }}/{{ result.stdout }}.d/macvlan.conf
  template:
    src: roles/router/templates/systemd/macvlan.conf
    dest: "{{ systemd_network_dir }}/{{ result.stdout }}.d/macvlan.conf"
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: copy aether-ue-nat.service to {{ systemd_system_dir }}/aether-ue-nat.service
  template:
    src: roles/router/templates/systemd/aether-ue-nat.service
    dest: "{{ systemd_system_dir }}/aether-ue-nat.service"
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: force systemd to reread configs
  systemd:
    daemon_reload: true
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: enable aether-ue-nat.service
  systemd:
    name: aether-ue-nat.service
    enabled: true
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: start aether-ue-nat.service
  systemd:
    name: aether-ue-nat.service
    state: started
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: restart systemd-networkd
  systemd:
    name: systemd-networkd
    state: restarted
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: "add iptable rule: forward from {{ core.data_iface }} to access"
  iptables:
    chain: FORWARD
    in_interface: "{{ core.data_iface }}"
    out_interface: access
    jump: ACCEPT
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: "add iptable rule: forward from access to {{ core.data_iface }}"
  iptables:
    chain: FORWARD
    in_interface: access
    out_interface: "{{ core.data_iface }}"
    jump: ACCEPT
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: "add iptable rule: forward from {{ core.data_iface }} to core"
  iptables:
    chain: FORWARD
    in_interface: "{{ core.data_iface }}"
    out_interface: core
    jump: ACCEPT
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: "add iptable rule: forward from core to {{ core.data_iface }}"
  iptables:
    chain: FORWARD
    in_interface: core
    out_interface: "{{ core.data_iface }}"
    jump: ACCEPT
  when: inventory_hostname in groups['master_nodes']
  become: true

- name: deploy sriov plugins
  block:
    - name: Get number of VF's available for the "{{ core.data_iface }}"
      shell: ip link show "{{ core.data_iface }}"|grep -c vf
      register: vf_status
      changed_when: false

    - debug:
         var=vf_status.stdout

    - name: verify the required VF resourses available in "{{ core.data_iface }}"
      ansible.builtin.assert:
        that:
          - vf_status.stdout | int >= 2

    - name: copy sriov-device-plugin.yaml to /tmp/sriov-device-plugin.yaml
      template:
        src: roles/router/templates/sriov-device-plugin.yaml
        dest: "/tmp/sriov-device-plugin.yaml"

    - name: copy sriov-device-plugin-config.yaml to /tmp/sriov-device-plugin-config.yaml
      template:
        src: roles/router/templates/sriov-device-plugin-config.yaml
        dest: "/tmp/sriov-device-plugin-config.yaml"

    - name: update proper data interface name in /tmp/sriov-device-plugin-config.yaml
      shell: sed -i -e "s/PFDEV/{{ core.data_iface }}/g" /tmp/sriov-device-plugin-config.yaml

    - name: apply /tmp/sriov-device-plugin.yaml
      shell: kubectl apply -f /tmp/sriov-device-plugin.yaml

    - name: apply /tmp/sriov-device-plugin-config.yaml
      shell: kubectl apply -f /tmp/sriov-device-plugin-config.yaml

    - name: Get Sriov Pods Status
      shell: kubectl get pods -A |grep sriov
      register: pod_status
      changed_when: false

    - name: restart sriov Pod
      shell: |
        while IFS= read -r line; do
          name=$(echo "$line" | awk '{print $2}')
          status=$(echo "$line" | awk '{print $4}')

          kubectl delete pod "$name"
        done <<< "{{ pod_status.stdout }}"
      args:
        executable: /bin/bash
  when: inventory_hostname in groups['master_nodes'] and core.upf.sriov
  always:
    - pause:
        seconds: 10
